# Realâ€‘Time Skin Lesion Classifier (TensorFlow + FastAPI) â€” macOS (Apple Silicon)

Endâ€‘toâ€‘end: data prep â†’ transfer learning (EfficientNetV2B0) â†’ Gradâ€‘CAM â†’ FastAPI deployment.

> **Disclaimer**: This is a technical demo, **not** a medical device.

---
# ðŸ©º Skin Lesion Classifier (HAM10000 + Grad-CAM)

A deep learning pipeline for **skin lesion classification** (benign vs malignant) using the [HAM10000 dataset](https://www.kaggle.com/kmader/skin-cancer-mnist-ham10000).  
Built with **TensorFlow 2.x**, trained on Apple Silicon (M1 GPU acceleration), and deployed via a **FastAPI inference server**.  

## ðŸš€ Features
- EfficientNetV2-B0 backbone (transfer learning).
- Binary classification: `benign` vs `malignant`.
- Training pipeline with `train.py`.
- Evaluation scripts: confusion matrix + classification report.
- Grad-CAM visualization to highlight regions influencing predictions.
- REST API server powered by FastAPI.
- Tested end-to-end on Apple M1 (Metal backend).

---

## ðŸ“‚ Repository Structure


## 0) Quick start on a new iMac (Apple Silicon)

### A) Oneâ€‘time system prep
```bash
# 1) Xcode command line tools (compilers, git)
xcode-select --install

# 2) Homebrew (package manager). If you already have it, skip.
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# 3) Miniforge (Conda for Apple Silicon)
brew install --cask miniforge
```
> After install, restart Terminal so `conda` is on PATH.

### B) Create your ML environment
```bash
# In the project folder:
conda create -n tf-mac python=3.11 -y
conda activate tf-mac

# For Apple Silicon GPU acceleration:
pip install --upgrade pip wheel setuptools
pip install -r requirements-apple-silicon.txt
```

### C) Verify TensorFlow + Metal
```bash
python scripts/test_tensorflow.py
```
You should see `mps` (Metal) listed as a device.

---

## 1) Data layout
Organize your dataset as:
```
data/
  train/
    benign/
    malignant/
  val/
    benign/
    malignant/
  test/
    benign/
    malignant/
```

---

## 2) Train the model
```bash
python train.py --epochs 10 --img-size 224 --batch-size 32
```
Artifacts:
- SavedModel â†’ `models/skin_model/`
- Class names â†’ `models/class_names.json`

---

## 3) Serve an API
```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```
Test:
```bash
curl -X POST "http://localhost:8000/predict" -F "file=@/path/to/image.jpg"
```

---

## 4) Gradâ€‘CAM
```bash
python utils/gradcam.py --image /path/to/image.jpg --out heatmap.jpg
```

---

## 5) Docker (optional)
```bash
docker build -t skin-api .
docker run -p 8000:8000 skin-api
```

---

## 6) TFLite (optional)
```bash
python scripts/convert_savedmodel_to_tflite.py
```

---

## 7) Dayâ€‘byâ€‘day refresh plan (10â€“14 days)

**Day 1â€“2:** macOS setup, env, sanity checks; skim TF/Keras basics.  
**Day 3â€“4:** Data ingestion + augmentation; baseline training run (5â€“10 epochs).  
**Day 5â€“6:** Fineâ€‘tune backbone; try different img sizes/batch sizes; record metrics.  
**Day 7:** Add Gradâ€‘CAM, sample visualizations; evaluate edge cases.  
**Day 8:** Wire up FastAPI; local prediction tests; log predictions.  
**Day 9:** Dockerize; run locally; simple cURL and HTTP tests.  
**Day 10â€“11:** Polish README; confusion matrix; precision/recall/F1 on `test`.  
**Day 12â€“13:** Optional cloud deploy (Render/Fly/EC2) and add tiny HTML upload UI.  
**Day 14:** Write a short LinkedIn/GitHub post; push repo public.

---

## 8) Notes for Intel Macs / Linux / Windows
Use `requirements-cpu.txt` instead of Apple Silicon. Create a venv or conda env, then:
```bash
pip install -r requirements-cpu.txt
```
